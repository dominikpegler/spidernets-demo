{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05eaa6a-a6ae-470c-86e6-89a4aa7af136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import io\n",
    "from model_loader import create_model\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transforms import get_data_transforms\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"/home\", \"user\", \"Dropbox\", \"data_export\", \"spidernets-analysis\")\n",
    "EXP_DIR = Path(DATA_DIR, \"experiments\")\n",
    "img_path = Path(DATA_DIR, \"stimuli\", \"Sp_040.jpg\")\n",
    "\n",
    "# run_id =\"0022\"\n",
    "run_id =\"2801\"\n",
    "fold = 1\n",
    "is_transformer = True\n",
    "\n",
    "transform = get_data_transforms(224, use_bicubic=is_transformer)[\"val\"]\n",
    "\n",
    "with open(Path(EXP_DIR, run_id, \"run_config.json\")) as fp:\n",
    "    run_config = json.load(fp)\n",
    "\n",
    "img_ar = cv2.imread(img_path)\n",
    "img_ar = cv2.cvtColor(img_ar, cv2.COLOR_BGR2RGB)\n",
    "img = Image.fromarray(img_ar)\n",
    "img = transform(img).unsqueeze(0)\n",
    "\n",
    "m = create_model(run_config, n_layers=3, dropout=0, data_dir=DATA_DIR)\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)\n",
    "\n",
    "checkpoint_path = Path(EXP_DIR, run_id, f\"fold_{fold}\", \"checkpoint_fine_tuning.pth\")\n",
    "\n",
    "with open(checkpoint_path, \"rb\") as fp:\n",
    "    checkpoint = CPU_Unpickler(fp).load()\n",
    "\n",
    "m.load_state_dict(checkpoint)\n",
    "\n",
    "m.eval();\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = m(img)\n",
    "    output = output.cpu().numpy().squeeze()\n",
    "\n",
    "# del m\n",
    "print(run_config[\"model_name\"])\n",
    "plt.imshow(img_ar)\n",
    "plt.title(f\"Fear: {output:.0f}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538daa54-5f11-4314-ae5d-552228d18c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_onnx = torch.onnx.export(m, img, dynamo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050aeef7-635a-4a4e-a4b4-6850e0f5d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_onnx.save(\"model.onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
